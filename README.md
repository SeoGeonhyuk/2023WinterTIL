# 2023WinterTIL
2023년 동계 모각소를 위한 TIL입니다.
# 20240119
# 1장-멀티스레딩

기존에 코드와 데이터로 저장되어 있던 프로그램이 실행되면 프로세스의 형태로 운영체제를 통해 관리되며, 이러한 프로세스는 메모리 위에 올려져 실행된다.

프로세스를 실행하기 전 컴파일러 된 부분에서 나오는 변수는 스택 부분에 올려진다.

프로세스를 통해 프로그램이 실행되면서 나오는 변수와 함수는 힙 부분에 올려진다.

프로세스가 여러 개 동시에 실행되고 있는 것을 멀티프로세싱이라고 한다.

프로세스에서는 여러 개의 스레드가 공존할 수 있으며, 이러한 스레드들은 힙을 통해 메모리를 공유한다. 하지만 스레드마다 스택을 가진다. 이러한 스택 내부에는 스레드에서 실행하는 함수의 로컬 변수들이 저장된다.

프로세스 하나를 메인 스레드 하나가 담당하는 것을 싱글스레드 모델

한 프로세스에 메인 스레드 뿐만 아니라, 부가적인 스레드들이 같이 해당 프로세스를 작동하는 것을 멀티스레딩이라고 한다.

이러한 멀티스레드를 사용할 때는 변수의 동기화를 유의해서 사용해야 한다.

다른 스레드로 인해서 변수의 값이 변경(race condition) 또는 메모리 주소값이 기존과 다르게 변경될 수도 있기 때문이다.

그래서 이러한 문제를 해결하기 위해 보통 스레드가 메모리를 참조하는 그러한 부분에 락을 걸어서 사용한다.

프로그램 실행 중 스레드가 변경되는 것을 컨텍스트 스위치라고 한다(이러한 컨텍스트 스위치는 CPU 코어의 개수보다 관리할 스레드의 개수가 많을 때 발생한다.)

이러한 컨텍스트 스위치는 언제 발생할지 알 수 없으므로 개발자의 멀티스레딩 의도대로 동작시키기 위해서 다양한 방법을 사용한다.

이러한 race condition이 발생하는 부분을 critical section이라고 하며, 이를 해결하기 위해서 뮤텍스, 이벤트, 세마포어 등을 활용한다.

컨텐션: 두 스레드가 동시에 한 데이터를 액세스하려고 하는 상황을 의미합니다. 두 스레드 중 하나 이상이 읽기 또는 쓰기를 할 때 뮤텍스로 잠금을 해서 보호하지 않으면 경쟁 상태가 발생하는 문제가 생깁니다. 또 뮤텍스로 잠금을 할 때는 한 스레드가 일을 하는 동안 다른 스레드가 모두 대기를 함으로써 병렬성이 사라지는 문제가 생깁니다. 이러한 컨텐션은 멀티스레드 프로그래밍에서 불가피합니다.

데드 락:서로의 스레드가 각각 다음에 참고해야 할 critical section 부분에 대한 락을 상대방이 가지고 있는 상태 이로 인해서 다음과 같은 문제가 발생할 수 있다.

1. CPU 사용량이 현저히 낮거나 0%입니다.
2. 클라이언트가 서버를 이용할 수 없습니다.

이러한 데드 락을 해결하기 위한 간단한 방법은 잠금 순서를 일관되게 정해두는 것이다.

A락, B락, C락이 있다면 순서를 A→B→C로 잠금 순서를 정하고 모든 스레드가 해당 방식으로 락을 거는 것이다.

예를 들어

B→C(o)

C→B(x)

A→B→C(o)

B→C→A(x)

가 된다.

락을 해제하는데는 순서가 상관없다.(B→A→C 등, 어떠한 순서로도 잠금해제를 해도 됨)

재귀 뮤텍스:한 스레드가 한 뮤텍스를 여러 번 잠금 해제 하는 것, 이렇게 여러 번 잠금을 할 경우, 잠금은 누적되며, 만약 잠금이 2번 중복되었을 경우 반드시 2번 해제해야 한다. 또한 재귀 뮤텍스는 잠금 순서의 규칙을 지키지 않아도 된다.

시리얼 병목:뮤텍스가 보호하는 영역이 너무 넓으면 스레드가 여럿이라 하더라도 하나일 때와 별반 차이가 없습니다. 여러 CPU가 각 스레드의 연산을 실행하여 동시 처리량을 올리는 것을 병렬성이라고 합니다. 그런데 어떤 이유로 이러한 병렬성이 제대로 나오지 않는 것, 즉 병렬로 실행되게 프로그램을 만들었는데 정작 한 CPU만 연산을 수행하는 현상을 시리얼 병목(serial bottleneck)이라고 합니다.

그리고 이러한 시리얼 병목이 있을 때 CPU의 코어 개수가 많아질 수록 다른 코어가 쉬는 시간은 코어 개수만큼 늘어납니다. 이러한 현상으로 인해 처리 효율성이 떨어지는 것을 암달의 법칙 또는 암달의 저주라고 한다.

이러한 암달의 저주를 줄이려면 시리얼 병목이 발생하는 구간을 최소로 줄여야 합니다.

TIP: 뮤텍스하는 부분 중에 디바이스 타임이 포함되어 있을 경우 해당 부분을 배제하고 뮤텍스를 건다.

요즘 클라이언트 개수만큼 스레드를 두면, 엄청나게 많은 컨텍스트 스위치가 일어나므로 그 대신 스레드 풀링 방법을 사용한다.

적절한 스레드 개수 지정 규칙

1. 어떤 서버의 주 역할이 CPU 연산만 하는 스레드라면(즉, 디바이스 타임이 없다면) 스레드풀의 스레드 개수는 서버의 CPU 개수와 동일하게 잡아도 충분합니다.
2. 서버에서 데이터베이스나 파일 등 다른 것에 액세스하면서 디바이스 타임이 발생할 때 스레드 개수는 CPU 개수보다 많아야 합니다.

원자 조작은 뮤텍스나 임계 영역 잠금 없이도 여러 스레드가 안전하게 접근할 수 있는 것을 의미한다.

멀티스레드 프로그래밍의 흔한 실수들

1. 읽기와 쓰기 모두에 잠금하지 않기
2. 잠금 순서 꼬임
3. 너무 좁은 잠금 범위
    1. 잠금 객체 범위가 너무 넓으면 컨텍스트 스위치가 일어날 확률이 높다.
    2. 잠금 객체 범위가 너무 좁으면 컨텍스트 스위치가 일어날 확률이 적지만, 잠금을 하는 과정과 이를 해제하는 과정에서 많은 처리 시간을 차지한다(물론 이는 디바이스 타임보다는 적다).
4. 디바이스 타임이 섞인 잠금
5. 잠금의 전염성으로 발생한 실수
6. 잠금된 뮤텍스나 critical section 삭제
7. 일관성 규칙 깨기

싱글스레드 프로세스가 다른 프로세스와 메시지를 주고받으면서 병렬 처리를 하는 모델을 일반화 한 것이 액터 모델이다.
# 20240126
# 2장-컴퓨터 네트워크, 3장-소켓 프로그래밍

## 2장

### 컴퓨터 네트워크 데이터

### 스트림 형식

스트림이란 데이터의 흐름입니다. 두 단말기를 연결한 후 그 연결을 끊기 전까지 한쪽에서 다른 한쪽으로 연결된 데이터 흐름 하나를 일컫습니다. 스트림 안에 있는 데이터를 중간에 끊는 것은 여러분의 몫이며, 스트림 자체는 데이터를 중간에 구별하지 않습니다. 

만약

aaa

bbb

ccc

라는 데이터가 있다면 스트림은 이를

aa

abbb

ccc

로 보낸다. TCP 프로토콜은 스트림을 통해 통신하기 때문에 해당 특성을 가진다.

따라서 스트림 형식으로 데이터를 송수신할 때, 데이터가 여러 부분으로 나뉘어 있다면 이것을 따로 정의해 주어야 한다. 예를 들어 어떤 데이터를 보내기 전에, 보낼 데이터 크기를 먼저 보낸다든지 데이터 시작이나 끝을 알리는 특정 기호를 추가하는 방법을 사용할 수 있다. 전자는 헤더를 붙이는 방식이라고 하며, 후자는 구분자를 이용하는 방식이라고 한다.

헤더 방식의 간단한 예

1. 첫 2바이트에는 보낼 데이터의 크기를 담는다.
2. 이어서 보낼 데이터를 담는다.

구분자 방식의 간단한 예

1. 보낼 데이터를 담는다.
2. 이어서 구분자를 담는다.

구분자 방식을 사용할 때 주의점

구분자 방식을 쓸 경우 구분자를 제외하고 보낼 데이터는 구분자와 같은 값이 없어야 한다. 예를 들어 구분자 값으로 0을 썼는데 보낼 데이터 중에 0이 있는 경우, 받는 측에서는 그것이 구분자인지 보낼 데이터인지 분간할 수 없습니다. 문자열 데이터는 문자열 끝을 의미하는 0 이외에는 0을 쓰는 일이 없습니다. 따라서 문자열을 전송할 때는 구분자로 0을 써도 안전합니다. 하지만 이진 데이터는 0도 데이터로써 유효한 값이 될 수 있습니다. 데이터 안에 구분자 값이 사용될 수 있으면서 구분자를 꼭 써야 할 때는 구분자와 데이터를 구별할 수 있는 별도의 알고리즘이 필요합니다. base64나 escape sequence처리 등이 그 예입니다.

### 메시지 형식

스트림과 달리 메시지는 자체적으로 데이터 시작과 끝을 구별할 수 있다. 

aaa

bbb

ccc

를 보내면

aaa

bbb

ccc

그대로 받는다.

이렇게 각 데이터가 정확히 구별되는 것을 메시지 형식이라고 한다.

메시지 형식은 데이터 시작과 끝을 구별할 필요가 없다. 메시지를 여러 필드로 나누어서 사용한다.

### 네트워크 품질 기준

1. 전송 속도
2. 패킷 유실률
3. 레이턴시

## 3장

### 블로킹 소켓

블로킹:디바이스에 처리 요청을 걸어 놓고 응답을 대기하는 함수를 호출할 때 스레드에서 발생하는 대기 현상.

블로킹 소켓:소켓에 대한 동기적인 입출력 방식

블로킹이 발생하는 스레드에서는 CPU 연산을 하지 않아 CPU 사용량이 0%가 된다. 즉, 스레드가 waitable state가 된다.

송신 버퍼가 꽉차면 송신 요청을 보낼 데이터 크기만큼의 분량이 송신 버퍼에 생길 때까지 대기한다. 그리고 공간이 생기면 .send함수가 실행되고 함수의 반환값을 바로 반환한다.

송신 버퍼는 디폴트로 수천 바이트를 담을 수 있다.

### 네트워크 연결받기 및 수신

```jsx
main(){
	s = socket(TCP); //1
	s.bind(5959); //2
	s.listen(); //3
	s2 = s.accept(); //4
	print(getpeeraddr(s2)); //5
	while(true){
		r = s2.recv(); //6
		if (r.length <= 0) //7
			break;
		print(r);
	}
	s2.close(); //8
}
```

1. TCP 소켓을 생성합니다.
2. TCP 포트 5959번을 점유합니다. TCP 포트 5959번이 이미 사용 중인 경우 이 함수는 실패합니다.
3. 이 소켓은 TCP 연결을 받는 역할을 시작하여 리스닝 소켓이 되었습니다. 이 함수는 즉시 리턴합니다.
4. TCP 연결이 들어올 때까지 기다립니다. 상대방 컴퓨터가 55.66.77.88:5959로 TCP 연결을 하면 이 함수는 리턴합니다. 리턴하면서 새로운 TCP 소켓의 핸들을 줍니다. 새로운 TCP 소켓은 5959번 이외에 다른 포트를 사용합니다. 여기서 알아야 할 것은 리스닝 소켓은 연결을 수락하는 역할만 할 뿐 데이터를 주고받는 용도로 사용되지 않는다는 것입니다.
5. accept() 함수에서 받은 새로운 소켓 핸들을 이용해서 저쪽 끝점과 통신을 합니다. 여기서 우리는 저쪽 끝점에 주소를 출력해 봅니다.
6. 새로운 소켓에서 데이터 수신을 합니다. recv()는 수신된 데이터를 리턴합니다만, 수신할 수 있는 데이터가 없으면 블로킹이 일어납니다. 수신할 수 있는 데이터가 있을 때까지 블로킹이 유지됩니다.
7. TCP 소켓에 대해 수신 함수를 호출했을 때 받은 데이터 크기가 0바이트라면 상대방이 tcp 연결을 끝냈음을 의미합니다.(그렇지 않다. 실제로는 0바이트를 보내서 연결을 종료하는 방식을 사용하지 않고 함수를 사용한다. 그러므로 해당 책에서의 자체적인 통신 종료 방법이다.) 그래서 여기서는 더 이상 수신을 시도하지 않습니다.(소켓에서 연결 돌발 끊어짐 등 오류가 발생하면 recv()는 음수를 리턴합니다. 이때도 더 이상 수신을 시도할 필요가 없습니다. 책 내용에 의사 코드에서는 지금 이것을 다루지는 않겠습니다. 여러분이 소켓 프로그래밍을 이해하는 데 오히려 방해가 될 수 있기 때문입니다. 그 대신 의사 코드에 첨부되어 있는 실제 구동되는 소스 코드를 참고하세요.)
8. 새로운 소켓의 연결이 끊어졌습니다. 이제 더 이상 사용할 수 없으므로 소켓을 닫습니다.

수신 버퍼 안에는 데이터가 수신되는 것이 있을 때마다 계속해서 채워 줍니다. 즉, 수신 버퍼를 방치하면 결국 꽉 차게 됩니다. 꽉 차면 더 이상 데이터를 받지 않습니다.

### 수신 버퍼가 가득 차면 발생하는 현상

TCP:보내는 쪽은 수신 버퍼가 비워질 때까지 블로킹 된다. 받는 쪽은 수신 버퍼에 데이터를 채우지 않고 사용자가 수신 버퍼에서 데이터를 꺼낼 때까지 대기한다.(이때 연결은 끊어지지 않고 유지 된다.)
UDP:수신 버퍼가 가득 차든 말든 상관없이 데이터를 일방적으로 보낸다. 이때 데이터가 손실될 수 있지만, 이를 보내는 쪽이 신경쓰진 않는다.

### 논블록 소켓

일대일 네트워킹 프로그램을 개발할 때는 지금까지 알아본 방법으로 개발을 해도 별 문제가 없다. 그러나 네트워킹을 해야 하는 대상이 여럿이라면?

네트워킹 대상 개수만큼 스레드를 만드는 방법이 있다. 그리고 각 스레드는 각각의 네트워킹 대상과 데이터를 주고받으면 된다. 이는 네트워킹 대상이 많지 않을 때는 별 문제가 없다. 그러나 수백 개, 수천 개라면? 각 스레드가 데이터 송수신을 처리하기 위해서 번번히 자다 깨다 할테고, 이 과정에 스레드 간에 컨텍스트 스위치가 대량 발생하고 이는 자원 낭비로 이어진다.

블로킹 현상이 일어난다⇒스레드 잠듦⇒컨텍스트 스위치⇒자원 낭비

그러므로 우리는 컨텍스트 스위치를 막아야 하고 다행히 소켓프로그래밍에서는 이를 방지하기 위해서 논블록 소켓모드를 지원한다. 논블록 소켓을 사용하는 방법은 크게 다음과 같습니다.

1. 소켓을 논블록 소켓으로 모드 전환합니다.
2. 논블록 소켓에 대해 평소처럼 송신, 수신, 연결과 관련된 함수를 호출합니다.
3. 논블록 소켓은 무조건 이 함수 호출에 대해 즉시 리턴합니다. 리턴 값은 ‘성공’ 혹은 ‘would block’ 오류 둘 중에 하나입니다.
4. would block일 경우에는 아무런 행위도 하지 않는다.

would block⇒블로킹에 걸릴 뻔했는데 논블록 소켓을 통해서 블로킹 상황을 막았다.

이러한 방식을 통해 기존 블로킹 상황을 억제하고 여러 스레드가 다른 일을 할 수 있도록 한다.

4번에서 would block일 경우에는 아무런 행위도 하지 않는다고 하였다. 하지만 connect 함수를 실행했고 그 반환 값이 would block일 경우에는 이야기가 다르다. 왜냐하면 이미 connect 함수를 통해서 소켓 안에서 무슨 일이 일어났다는 뜻이기 때문이다. 소켓은 상대방의 TCP 연결 끝점으로 연결을 시도하다가 would block이 된 것이므로 소켓은 이미 ‘연결 과정이 진행 중인 상태’로 변한다. 그러므로 connect의 재실행을 막기 위해서는 별다른 조치를 취해야 한다. 그 해결 방법 중 ‘0바이트 송신’이 있다. TCP는 스트림 기반 프로토콜이기 때문에 0바이트를 보내는 것은 사실상 아무것도 하지 않는다는 뜻이다. 그러므로 0바이트를 보내는 것이 성공한다면 해당 연결이 성공적으로 이루어진 것이라고 볼 수 있다.

<img width="640" alt="Untitled" src="https://github.com/SeoGeonhyuk/2023WinterTIL/assets/60954160/f15ef8c6-bf67-4402-a37b-8dfd2121a75e">
<br>

### 논블록 소켓의 문제점

논블록 소켓은 would block인 경우 해당 소켓 연결은 잠깐 놔두고 다른 소켓을 찾아서 작업을 실행한다. 이 방식은 cpu의 코어 한 개를 100퍼센트 점유하여 운영하는 방식이고 이로 인해서 CPU는 쉬지 않게 된다. 하지만 이는 문제가 될 수 있다. 서버는 특별한 일이 없는 한 CPU가 최대한 놀고 있어야 한다. 그래야 다른 일을 처리할 수 있는 여유를 확보할 수 있다. 그러므로 논블록 소켓은 서버의 CPU를 너무 과하게 점유할 수 있는 문제가 발생한다.

이를 해결하기 위해서는 다음과 같은 요소를 고려해야 한다.

1. 여러 소켓 중 하나라도 would block이었던 상태에 변화가 일어나면, 즉 송신 버퍼에 빈 공간이 생기거나 수신 버퍼에 뭔가가 들어온다면 그 상황을 알려 주는 함수
2. 혹은 그것을 알려주기 전까지는 블로킹 중이어서 CPU 사용량 폭주를 해결하는 함수

이러한 기능을 제공하는 함수가 있다.

1. 소켓 리스트 A를 입력합니다.
2. A에 있는 소켓 중 하나라도 I/O 처리를 할 수 있는 것이 생기는 순간까지 블로킹합니다.
3. 블로킹이 끝나면 어떤 소켓이 I/O 처리를 할 수 있는지 알려 줍니다.
4. 블로킹은 타임아웃을 지정할 수 있습니다. ‘무한대’를 입력하면 I/O 처리를 할 수 있는 소켓이 생길 때까지 영원히 기다립니다. 지정한 시간(밀리초 단위)을 입력하면 해당 시간이 될 때까지 기다립니다. 0초를 입력하면 블로킹 없이 결과를 리턴합니다.

이 작업은 select() 또는 poll()을 통해서 할 수 있다.

### Overlapped I/O 혹은 비동기 I

논블록 소켓의 장점은 다음과 같다.

1. 스레드 블로킹이 없으므로 중도 취소 같은 통제가 가능합니다.
2. 스레드 개수가 1개이거나 적어도 소켓을 여러 개 다룰 수 있습니다.
3. 스레드 개수가 적거나 1개이므로 연산량이 낭비되지 않습니다. 그리고 호출 스택 메모리도 낭비되지 않습니다.

그러나 단점도 있다.

1. 소켓 I/O 함수가 리턴한 코드가 would block인 경우 재시도 호출 낭비가 발생합니다.
2. 소켓 I/O 함수를 호출할 때 입력하는 데이터 블록에 대한 복사 연산이 발생합니다.
3. connect() 함수는 재시도 호출을 하지 않지만, send() 함수나 receive() 함수는 재시도 호출해야 하는 API가 일관되지 않는다는 문제점이 있습니다.

논블록 소켓에서 재시도용 호출의 낭비가 어떤 경우에 있는지 알아봅시다.

TCP소켓의 send() 처리 부분을 살펴봅시다. 이는 송신 버퍼에 1바이트라도 비어 있으면 I/O 가능이 됩니다. 이 상태에서 TCP 소켓에 대해 send() 함수를 호출하면 would block은 절대 발생하지 않습니다. 보내려는 데이터가 5바이트인데 송신 버퍼에 빈 공간이 1바이트라면, 1바이트만 소켓 송신 버퍼에 채워집니다. 그리고 성공적으로 리턴합니다. 즉 보낼 데이터의 일부만 성공적으로 송신 큐에 넣었지만 어쨌든 결론적으로는 문제가 없다.

이제 TCP 소켓의 receive() 처리 부분도 살펴봅시다. 수신 버퍼에 1바이트라도 들어 있으면 I/O 가능이 됩니다. 이 상태에서 TCP 수신, 즉 recv() 함수를 호출하면 수신 버퍼에 있는 것을 꺼내옵니다. 따라서 would block이 생기지 않으며 UDP 소켓의 receive() 처리 역시 문제가 없습니다. 이유는 소켓의 receive() 처리 때와 같습니다.

하지만 UDP 소켓의 send() 처리에서는 문제가 있습니다.

UDP 소켓의 송신 버퍼에 1바이트라도 비어 있으면 I/O 가능입니다. 그런데 보내려는 데이터가 5바이트인데 송신 버퍼 빈 공간이 1바이트라면, 넣을 수 있는 크기를 넘어섭니다. TCP와 달리 UDP는 일부만 보낼 수 없으므로 would block이 발생합니다. ‘헛발질’이 발생한 셈입니다. I/O 가능이라 재시도는 했는데, 여전히 would block입니다. 이 상태로라면 UDP send()하지 못한 채 계속 헛발질만 반복합니다. 이는 결국 CPU 낭비로 이어집니다. 

논블록 소켓은 소켓 함수 내부의 데이터 복사 부하라는 또 다른 단점이 있습니다.

소켓 송수신 함수에 들어가는 데이터 블록 인자를  성공적으로 실행하면 다음과 같이 기존 데이터를 송신 버퍼에 복사해야 하는 낭비적인 연산이 발생합니다.

안타깝게도 RAM은 느린 부품입니다. CPU 안에 있는 캐시 메모리에 메모리 내용이 복사되어 있으면 데이터 액세스는 매우 빠릅니다. 하지만 캐시에 없는 데이터를 액세스할 때는 메인 메모리 RAM을 액세스하는데, 이 속도는 매우 느립니다. 물론 하드디스크나 네트워크 데이터보다는 빠르겠지만요, 따라서 고성능 서버를 개발할 때는 이 복사 연산도 무시할 수 없는 변수인 셈입니다.

지금까지 설명한 것을 한꺼번에 해결하는 기법이 Overlapped 또는 Asynchronous(비동기) I/O 입니다. 이는 재시도용 호출 낭비 문제와 소켓 함수에 데이터 블록 복사 부하 문제를 모두 해결해 줍니다.

앞서 본 논블록 소켓은 다음 데이터를 다룹니다.

1. 소켓이 I/O 가능인 것이 있을 때까지 기다립니다.
2. 소켓에 대해 논블록 액세스를 합니다.
3. would block이 발생했으면 그대로 두고, 그렇지 않으면 실행 결과 리턴 값을 처리합니다.

Overlapped I/O에서는 다르게 합니다.

1. 소켓에 대해 Overlapped 액세스를 “겁니다.”
2. Overlapped 액세스가 성공했는지 확인한 후 성공했으면 결과값을 얻어와서 나머지를 처리합니다.

Overlapped I/O는 논블록 소켓과 비교했을 때 성능상 유리합니다. 하지만 백그라운드 액세스로 인해서 운영체제가 데이터를 조작할 수 있다는 단점이 있습니다. 그래서 운영체제가 데이터를 조작할 수 있게 하기 위해서 호출한 Overlapped I/O 전용 함수가 비동기로 하는 일이 완료될 때까지는 소켓 API에 인자로 넘긴 데이터 블록을 제거하거나 내용을 변경해서는 안 됩니다.

epolll은 소켓이 I/O 가능 상태가 되면 이를 감지해서 사용자에게 알림을 해 주는 역할을 합니다. 이때 어떤 소켓이 I/O 가능 상태인지 알려 줍니다.

<img width="325" alt="스크린샷 2024-01-27 오전 10 10 41" src="https://github.com/SeoGeonhyuk/2023WinterTIL/assets/60954160/e5fb5c05-45d5-41e8-92eb-43f7750762c8">
<br></bt>
<img width="244" alt="스크린샷 2024-01-27 오전 10 07 32" src="https://github.com/SeoGeonhyuk/2023WinterTIL/assets/60954160/952e8a05-0d8e-4038-91a3-142354963b4d">

또한 epoll은 기존과 달리 엣지 트리거를 통하여 동작합니다. 이러한 엣지 트리거 위주의 동작으로 인해 사용자는 기존 select 함수를 통해서 전체 소켓을 가져오는 것보다 현재 가능한 소켓만 가져올 수 있게 됩니다. 하지만 이 역시 단점이 있습니다. 엣지 트리거로만 작동되기에 기존에 레벨 트리거 상태에서 값을 받았을 때 더 받을 수 있는 상태일 경우에 엣지트리거의 변동이 없기 때문에 epoll은 해당 소켓을 인식하지 못하게 됩니다.

따라서 엣지 트리거를 쓸 때는 다음 상항을 주의해야 합니다.

1. I/O 호출을 한 번만 하지 말고 would block이 발생할 때까지 반복해야 합니다.
2. 소켓은 논블록으로 미리 설정되어 있어야 합니다.

# 4장-게임서버와 클라이언트

dedicated server:순전히 클라이언트의 연결을 받는 세션을 처리만 하는 프로그램

싱글플레이 게임을 처리하기 위해 컴퓨터는 다음 과정을 반복한다.

1. 입력받기:키보드, 마우스, 터치 스크린, 마이크, 카메라 등으로 컴퓨터가 정보를 획득하는 과정입니다.
2. 게임 로직 처리하기:게임 정보를 담고 있는 상태인 세션은 보통 1초에 60번 상태 변화를 합니다. 상태 변화를 하는 과정을 게임 로직 처리라고 합니다. 게임 로직 처리 과정 중에는 게임 플레이 판정, 가령 플레이어가 어느 캐릭터에 대미지를 주었는지 혹은 캐릭터가 어느 몬스터 캐릭터에 대미지를 받았는지 등을 계산합니다.
3. 렌더링:변호된 상태를 화면에 표현합니다.

이 세 과정을 반복하는 것을 게임 루프라고 한다.

온라인 게임에서는 클라이언트에서 게임 로직을 처리하는 역할 일부를 떼어 서버로 옮긴다. 그리고 클라이언트와 서버 간에는 컴퓨터 네트워크를 통해 서로 데이터를 주고받는다.

### 게임 클라이언트와 서버의 상호 작용

게임 클라이언트와 서버의 상호 작용은 크게 네 가지로 구별된다.

1. 연결
2. 요청-응답(클라이언트가 서버에 요청을 하고 서버가 이에 대해서 응답해주는 것⇒상호작용)
3. 능동적 통보(서버가 클라이언트에게 상대를 일방적으로 전달해주는 것⇒상호작용이 아님)
4. 연결 해제

### 게임 서버가 하는 일

1. 여러 사용자와 상호 작용
2. 클라이언트에서 해킹당하면 안되는 처리:플레이어 개인정보 등의 로직 처리
3. 플레이어의 상태 보관:클라이언트가 플레이어의 상태를 가지고 있을 경우 플레이어의 상태를 조작하여 게임 환경을 어지럽게 만들 수 있음, 그러므로 플레이어의 상태를 서버에서 보관하여 이러한 현상을 막아야 함

### 게임 서버의 품질

1. 안정성
    1. 게임 서버가 얼마나 죽지 않는가
    2. 안정성을 위해 노력할 것
        1. 치밀한 개발과 유닛 테스트
        2. 80:20법칙:모든 프로그램 성능의 80%는 20%의 소스 코드에서 나타난다는 파레토 법칙입니다. 성능에 지대한 영향을 주는 일부분의 소스 코드에서만 프로그램 구조가 복잡해지더라도 성능을 최적화해서 개발하고, 나머지 대부분은 성능보다 유지 보수하기 쉬운 단순한 구조로 개발하는 것입니다.
        3. 1인 이상의 코드 리뷰
        4. 가정하지 말고 검증하라
2. 확장성
    1. 크게 수직확장과 수평확장으로 볼 수 있음
    2. 수직확장:단일 게임 서버의 성능을 업그레이드 하는 것, 서버 소프트웨어 설계 비용은 낮지만 확장 비용이 기하급수적으로 높아질 수도 있다.
    3. 수평확장:같은 사양의 서버 머신의 개수를 증가시키는 것, 서버 소프트웨어 설계 비용은 높지만(이러한 시스템을 적용하려면 서버의 확장성을 고려해야 하기 때문이다.) 확장 비용은 수직확장보다 상대적으로 낮다.
        1. 수평적 확장은 소프트웨어 구조가 복잡해지는 것 뿐만아니라, 특정 데이터 처리를 여러 서버에 걸쳐서 작동해야 하는데, 여기서 다양한 문제가 발생한다. 그리고 기본적으로 컴퓨터 한 대 안에서 발생하는 처리 속도보다 여러 컴퓨터에 걸쳐서 처리하는 속도가 훨씬 느리다. 그러다 보니 서버 간 상호 작용하는 처리에서 성능 하락이나 예전 데이터를 다루는 에러 현상이 발생하기도 한다.
        2. 수평적 확장은 단위 처리 성능에도 악영향을 준다. 클라이언트가 어떤 메시지를 처리하는 과정은 다음과 같다. 유저 프로세스→커널→디바이스→회선→라우터→회선→디바이스→커널→유저프로세스 이 과정에서 버퍼링으로 인한 지연 시간이 발생한다. 게다가 TCP 네트워크 특성상 Nagle 알고리즘이 작용하거나 서버 간 통신 자체가 과부하를 일으키면 원치 않는 지연 시간이 추가로 발생할 수도 있다.
        3. 결국 수평적 확장은 수직 확장보다는 느리지만 총 처리량이 크게 증가한다.
    4. 수직적 확장은 단위 성능과 구조 측면에서 유리하지만 확장성에 한계가 있다. 수평적 확장은 그 반대이지만, 확장성을 결국 해결한다. 많은 대용량 서버에서는 수평적 확장이 고려되어 설계되지만, 개발의 경제성과 성능을 위해 실제로는 수평적 확장과 수직적 확장을 혼합해서 설계한다.
3. 성능
    1. 성능과 확장성은 다르다. 확장성은 사용자가 많아지더라도 서버가 처리하는 속도가 하락하지 않게 하는 것과 관련이 있다. 하지만 성능은 기본적으로 요구사항을 얼마나 빨리 처리하는지에 대해서 관련이 있다.
    2. 이러한 성능은 컴퓨터 사양 뿐만 아니라, 네트워크 속도에 따라서도 결정된다.
    3. 서버의 성능을 높이는 방법은 부하가 심한 기능에 대해서 최적화(길찾기에 대해서 path table 테크닉을 적용하여 O(1)으로 개선)를 하거나 분산 처리 시스템을 구상하거나 네트워크 프로토콜을 최적화 하거나 메시지 양을 압축하여 줄이는 방법 등이 있다.
4. 관리 편의성
    1. 서버에 대한 관리가 편한 것

### 서버 개발 지침

코드의 양이 적더라도 한 줄 한 줄 안정적으로 만드는 것이 중요하다.

### UML

UML을 사용하여 데이터 정의와 프로세스 정의를 우선적으로 실시한다. 프로그램 구조 명세를 표현하는 대표적인 수단. 이러한 UML은 여러 가지 방식이 있지만 여기서는 시퀀스 다이어그램, 액티비티 다이어그램만 다룬다.

1. 시퀀스 다이어그램
![k](https://github.com/SeoGeonhyuk/2023WinterTIL/assets/60954160/1257bf0d-8a7d-483d-96ab-81f0aa2721b6)

    
2. 액티비티 다이어그램
![j](https://github.com/SeoGeonhyuk/2023WinterTIL/assets/60954160/a9703b6a-7481-4c1d-83fe-59d98046dd5e)

    

### 게임 플레이 네트워킹

1. 모든 역할을 서버에서 하기
    1. 사용자는 키 입력과 화면 출력을 하고 나머지 게임 로직 연산, 화면 렌더링, 화면 송출을 담당하는 것
    2. 단점
        1. 서버가 멀리 있으면 네트워킹 중에 레이턴시가 추가된다.
        2. 클라우드 서버 안에서 가상 머신은 다른 가상 머신의 CPU 사용량을 잠식하면서 조금씩 지연 시간이 있을 수 있다.
        3. 패킷 드롭으로 인한 재송신은 간헐적인 큰 지연 시간을 일으킨다.
        4. 인구가 낮은 국가에서는 인터넷이 느리다.
        5. 무선 네트워크에서는 레이턴시와 패킷 드롭률이 크게 증가한다.
        6. 서버 컴퓨터의 사양이 압도적으로 좋아야 하고 이를 위해서는 막대한 비용이 든다.
2. 렌더링은 클라이언트에서 하기
    1. 기존에 사용자가 키 입력과 화면 출력 뿐만 아니라 렌더링까지 같이 하는 것을 말한다.
    2. 기존 모든 역할을 서버에서 하는 것보다 효율이 좋다.
    3. 단점
        1. 레이턴시로 인해서 발생하는 캐릭터의 위치 부자연스러움 문제
        2. 이를 해결하기 위해서 상태값 보정을 해야 하고 이러한 해결 방법은 다양하게 있음
        3. 대표적으로 선형보간, 스플라인, 추측항법 등을 사용함 그리고 이러한 해결 방법들을 레이턴시 마스킹이라고 함
        4. 또한 서버에 들어오는 정보량을 줄이기 위해서 사용자 입장에서 가시적인 부분만 정보를 보내는 방법도 있음

### 실시간 전략 시뮬레이션 게임에서 네트워크 동기화

락스텝 동기화 알고리즘 사용

https://sanghun219.tistory.com/27

### 보안과 해킹

클라이언트 컴퓨터가 해킹당하거나 서버 컴퓨터가 해킹당해서 다양한 문제가 일어날 수 있음

대표적인 문제 query injection

이러한 문제를 해결하기 위해서 노력해야 함

해결 방법 대칭키 알고리즘, 질의 구문을 변경하는 것 등 다양한 방법이 존재함.

## 9장

스케일 업⇒수직확장

스케일 아웃⇒수평확장

분산 처리 기능을 구현하기 전에 일단 단일 서버를 통한 게임 구현을 한 뒤, 서비스 운영을 하면서 분산 처리 지점을 찾아내고 필요에 따라 분산 시스템 도입을 고려할 것

### 분산 단위와 분산 처리 방식

### 분산 단위

1. 데이터 단위 분산
    1. 데이터를 나눠서 처리
2. 기능 단위 분산
    1. 기능 별로 나눠서 처리
    2. 최후의 수단, 일단 데이터 단위 분산을 우선적으로 할 것을 권장

### 분산 처리 방식

1. 동기 분산 처리
    1. 어떤 서버에서 다른 서버로 연산 기능을 맡겨두고 다른 서버의 응답이 올 때까지 기다리는 것
    2. 기다리는 것 뿐만 아니라 그 연산과 관계된 데이터가 도중에 변경되지 않게 잠금해서 데이터의 안정성을 유지해야 한다.
    3. 동기 분산 처리는 동기식 명령 처리법 동기식 데이터 변경법 두 가지가 있다.
        1. 동기식 명령 처리는 데이터를 다른 서버에서 가져오지 않고 그쪽에 필요한 정보만 넘겨준 다음 처리를 맡기는 것
        2. 동기식 데이터 변경법은 데이터를 가지고 있는 다른 서버에서 가져온 다음 서버 내부에서 처리를 하고 다시 그 변경된 데이터를 다른 서버에 넘겨주는 것
    4. 동기 방식으로 인해 대기 시간이 있을 수 있다. 동기 방식으로 인해서 동시접속자가 낮아질 수 있다.
    5. 이 문제를 개선하기 위해서 멀티스레드 혹은 멀티프로세싱 방법을 도입하거나 뮤텍스의 잠금 범위를 좁히거나 연결이 필요한 서버들을 Infiniband로 묶는 방법이 고려될 수 있다.
2. 비동기 분산 처리
    1. 비동기 분산 처리 방식은 다음과 같은 과정을 거친다.
        1. 서버 1은 어떤 연산 명령을 다른 서버2에 송신한다.
        2. 서버 1은 서버 2의 명령 처리 결과를 기다리지 않고 다른 일을 시작한다.
    2. 비동기 분산은 동기 분산과 달리 잠금으로 인한 병목 현상이 없고 서버가 가진 성능을 최대한 활용할 수 있다.
    3. 모든 로직을 이 방식으로 구현하기 어렵거나 불가능하다.(보통 간단한 데미지 처리 함수 정도는 가능)
    4. 그렇기 때문에 운영체제가 해당 메시지 또는 스트림을 보내는 과정에서 배보다 배꼽이 더 큰 상황이 발생할 수 있다.(간단한 기능의 기계어 200~300개, 다른 서버에서 그 요청을 보내고 다시 받는 기능에 대한 기계어 수천개)
3. 데이터 복제에 기반을 둔 로컬 처리
    1. 각 서버마다 똑같은 데이터를 가지고 있고 한 개의 서버가 여러 가지 이유로 데이터를 변경했을 경우 그 변경된 데이터의 정보를 다른 서버에 전파하는 방식
    2. 단점
        1. 데이터 전파 속도가 느리기 때문에 stale data problem이 발생할 수 있고 이로 인해서 하이젠버그 현상이 발생할 수 있다.
        2. 데이터 응집도를 측정하고 이에 따라 서버를 설계하면서 최대한 적은 서버에 해당 내용을 전파시킴으로써 어느 정도 문제를 해결할 수 있다.

### 분산 처리를 엄선해야 하는 이유

1. 분산 처리는 여러 가지 위험성을 고려해야 하기 때문
2. 지나친 분산 처리는 네트워크 장비에 부하 몰림, 네트워크 장비 과부하로 서비스 장애를 일으킬 수 있다.
3. 분산 처리 프로그램은 디버깅이 까다롭다.
4. 운영체제가 해야 하는 일을 불필요하게 증가시킨다.

### 분산 처리 전략

1. 성능 분석을 하여 분산 처리가 필요한 지점을 엄선해라.
2. 데이터 응집력을 확인해라
3. 분산 처리 방식을 다양하게 고려해봐라(동기 분산 처리, 비동기 분산 처리, 데이터 동기화에 기반을 둔 로컬 처리 등)
4. 분산 처리는 불필요한 과부하를 일으킬 수 있다. 불필요한 분산 처리는 가급적 피해라.

### 고가용성:사용자가 항상 서비스를 이용할 수 있게 하는 것

1. 고가용성을 위한 서버 구성 패턴에는 여러 가지가 있다.
    1. 액티브-패시브 패턴(마스터-슬레이브 패턴)
    2. 액티브-액티브 패턴
    3. stale data problem 문제를 해결하기 위해서 공유 메모리 저장 서버를 두어서 처리할 수 있다.
2. 이러한 고가용성 서버를 다룰 때는 다수의 서버를 쉽게 관리하는 서버 오케스트레이션 도구를 사용한다.

### 데이터베이스의 분산

1. 게임 서버가 분산 처리되어 있다고 해도, 데이터베이스를 분산 처리하지 않으면 서비스 가용성이 떨어질 수 있음
2. 데이터베이스의 레코드를 나누는 것을 파티셔닝이라고 한다.
3. 테이블 각각을 다른 데이터베이스 서버에 나눠놓기도 하는데 이런 경우를 수직 파티셔닝이라고 한다.
4. 데이터베이스도 이중화(액티브-패시브) 기법을 사용하기도 한다.

### 요약

1. 분산 서버
    1. 서버 한 대가 처리할 수 없는 양을 여러 대가 나누어서 처리하는 것.
2. 서버 클러스터
    1. 서버 여러 대의 집합.
3. 수평 확장
    1. 서버 개수를 늘려서 총 처리량을 늘리는 것.
4. 샤드
    1. 거대한 데이터를 여러 서버 기기로 분산한 후 데이터 일부를 지닌 각 서버 기기를 지칭한다.
5. 로드 밸런싱
    1. 한쪽에 과부하가 몰리는 것을 다른 서버와 분배하는 것.
6. 고가용성
    1. 서버 하드웨어나 소프트웨어가 죽더라도 사용자 입장에서 계속해서 서비스를 이용할 수 있는 것.
